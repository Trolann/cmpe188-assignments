{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac78dd70",
   "metadata": {},
   "source": [
    "# Aaron, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19feef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from perform_kickstarer_eda import X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "476c7b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(tf.__version__)\n",
    "\n",
    "# Split the training data into a smaller training set and a validation set\n",
    "X_train_small, X_val, y_train_small, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e6c3cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (13200, 66)\n",
      "y_train shape: (13200,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "def build_model(hidden_units=(64,), activation='relu', optimizer='adam', learning_rate=0.001):\n",
    "    inputs = Input(shape=(X_train.shape[1],))\n",
    "    x = inputs\n",
    "    for units in hidden_units:\n",
    "        x = Dense(units, activation=activation)(x)\n",
    "    outputs = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    if optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "print(\"X_train shape:\", X_train_small.shape)\n",
    "print(\"y_train shape:\", y_train_small.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae0da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GridSearchCV to find the best hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "regressor = KerasRegressor(\n",
    "    model=build_model,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'model__hidden_units': [(16,), (32,), (64,), (128,), (256,), (32,16), (64, 32), (128, 64),(64, 32, 16)],\n",
    "    'model__activation': ['relu', 'tanh', 'logistic', 'identity'],\n",
    "    'model__optimizer': ['adam', 'sgd'],\n",
    "    'model__learning_rate': [0.001, 0.01],\n",
    "    'epochs': [50, 100, 200],\n",
    "    'batch_size': [16, 32, 64]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=regressor, param_grid=param_grid, cv=5)\n",
    "grid_result = grid.fit(X_train, y_train) # Using X_train instead of X_train_small as GridSearchCV handles validation split\n",
    "\n",
    "\n",
    "print(\"Best Params:\", grid_result.best_params_)\n",
    "print(\"Best MSE:\", -grid_result.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model = grid_result.best_estimator_.model_\n",
    "mse, mae = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test MSE: {mse:.4f}, MAE: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas import DataFrame\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# # Test multiple architectures\n",
    "# architectures = [\n",
    "#     [16],\n",
    "#     [32],\n",
    "#     [64],\n",
    "#     [128],\n",
    "#     [256],\n",
    "#     [32, 16],\n",
    "#     [64, 32],\n",
    "#     [128, 64],\n",
    "#     [64, 32, 16],\n",
    "# ]\n",
    "\n",
    "# results = []\n",
    "# for arch in architectures:\n",
    "#     print(f\"Testing architecture: {arch}\")\n",
    "#     result = create_and_evaluate_model(arch, X_train_small, y_train_small, X_val, y_val, X_test, y_test)\n",
    "#     results.append({\n",
    "#         \"architecture\": str(arch),\n",
    "#         \"mse\": result[\"mse\"],\n",
    "#         \"mae\": result[\"mae\"],\n",
    "#         \"r2\": result[\"r2\"]\n",
    "#     })\n",
    "\n",
    "# # Display results as a table\n",
    "# results_df = DataFrame(results)\n",
    "# print(\"\\nResults comparison:\")\n",
    "# print(results_df)\n",
    "\n",
    "# # Plot comparison - only include rows without NaN values\n",
    "# valid_results = results_df.dropna()\n",
    "# if len(valid_results) > 0:\n",
    "#     plt.figure(figsize=(12, 5))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.bar(valid_results[\"architecture\"], valid_results[\"r2\"])\n",
    "#     plt.title(\"R² Score by Architecture\")\n",
    "#     plt.xlabel(\"Architecture\")\n",
    "#     plt.ylabel(\"R² Score\")\n",
    "#     plt.xticks(rotation=45)\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.bar(valid_results[\"architecture\"], valid_results[\"mse\"])\n",
    "#     plt.title(\"MSE by Architecture\")\n",
    "#     plt.xlabel(\"Architecture\")\n",
    "#     plt.ylabel(\"Mean Squared Error\")\n",
    "#     plt.xticks(rotation=45)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "# else:\n",
    "#     print(\"No valid results to plot comparisons\")\n",
    "\n",
    "# # Cross-validation comparison with Linear Regression\n",
    "# print(\"\\nPerforming cross-validation comparison...\")\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# mlp_cv_scores = []\n",
    "# lr_cv_scores = []\n",
    "\n",
    "# for train_idx, val_idx in kf.split(X_scaled):\n",
    "#     # Get fold data\n",
    "#     X_fold_train, X_fold_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "#     y_fold_train, y_fold_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "#     # Train and evaluate MLP with best architecture\n",
    "#     tf.keras.backend.clear_session()\n",
    "#     inputs = tf.keras.layers.Input(shape=(X_fold_train.shape[1],))\n",
    "#     x = tf.keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
    "#     x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "#     outputs = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "#     fold_mlp = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "#     fold_mlp.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "#     fold_mlp.fit(X_fold_train, y_fold_train, epochs=50, verbose=0)\n",
    "\n",
    "#     try:\n",
    "#         y_pred_fold_mlp = fold_mlp.predict(X_fold_val).flatten()\n",
    "#         # Check for NaN values\n",
    "#         if isnan(y_pred_fold_mlp).any():\n",
    "#             print(\"Warning: NaN values in MLP predictions for this fold\")\n",
    "#             # Use only non-NaN predictions\n",
    "#             mask = ~isnan(y_pred_fold_mlp)\n",
    "#             if mask.sum() > 0:\n",
    "#                 mlp_cv_scores.append(r2_score(y_fold_val.iloc[mask], y_pred_fold_mlp[mask]))\n",
    "#             else:\n",
    "#                 mlp_cv_scores.append(nan)\n",
    "#         else:\n",
    "#             mlp_cv_scores.append(r2_score(y_fold_val, y_pred_fold_mlp))\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in MLP cross-validation: {e}\")\n",
    "#         mlp_cv_scores.append(nan)\n",
    "\n",
    "\n",
    "# # Filter out NaN scores\n",
    "# mlp_cv_scores_filtered = [score for score in mlp_cv_scores if not isnan(score)]\n",
    "\n",
    "# if mlp_cv_scores_filtered:\n",
    "#     print(f\"MLP Cross-Validation R² scores: {mlp_cv_scores}\")\n",
    "#     print(f\"MLP Cross-Validation Mean R²: {mean(mlp_cv_scores_filtered):.4f}\")\n",
    "# else:\n",
    "#     print(f\"MLP Cross-Validation R² scores: {mlp_cv_scores}\")\n",
    "#     print(\"No valid MLP cross-validation scores\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
