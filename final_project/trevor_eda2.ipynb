{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Names, title, etc",
   "id": "9ecd369fe75dfeb"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "DONT_RUN_LONG_CELLS = True\n",
    "from pandas import read_csv\n",
    "kickstarter_filename = 'kickstarter_data_full.csv'\n",
    "kickstarter_filename_features = 'kickstarter_data_with_features.csv'\n",
    "\n",
    "ks_data = read_csv(kickstarter_filename)\n",
    "ks_feat_data = read_csv(kickstarter_filename_features)\n",
    "data_list = [('ks_data', ks_data), ('ks_feat_data', ks_feat_data)]\n",
    "# print columns not present in the other dataset\n",
    "ks_data_columns = set(ks_data.columns)\n",
    "ks_feat_data_columns = set(ks_feat_data.columns)\n",
    "\n",
    "ks_data_not_in_feat = ks_data_columns - ks_feat_data_columns\n",
    "ks_feat_data_not_in_ks = ks_feat_data_columns - ks_data_columns\n",
    "\n",
    "print(f'Columns in ks_data not in ks_feat_data: {ks_data_not_in_feat}')\n",
    "print(f'Columns in ks_feat_data not in ks_data: {ks_feat_data_not_in_ks}')\n",
    "\n",
    "common_columns = ks_data_columns.intersection(ks_feat_data_columns)\n",
    "\n",
    "# of common columns, compare the values and see if they match\n",
    "for column in common_columns:\n",
    "    ks_data_values = ks_data[column].unique()\n",
    "    ks_feat_data_values = ks_feat_data[column].unique()\n",
    "    if len(ks_data_values) != len(ks_feat_data_values):\n",
    "        print(f'Column {column} has different number of unique values: {len(ks_data_values)} vs {len(ks_feat_data_values)}')\n",
    "    else:\n",
    "        pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "60d570cadfcc73dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## So we know ks_data is the dataset to use as it has more data, more unique data",
   "id": "7fd36a9b5d4c34f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_list = [('ks_data', ks_data), ('ks_feat_data', ks_feat_data)]\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import set_option\n",
    "\n",
    "\n",
    "def data_info(_data, show_scatter=False):\n",
    "    print(f'Data head: {_data.head(5)}')\n",
    "    print(f'Null values: {_data.isnull().sum()}')\n",
    "    print(f'Data Shape: {_data.shape[0]} rows and {_data.shape[1]} columns')\n",
    "    print(f'Columns: {list(_data.columns)}')\n",
    "    for column in _data.columns:\n",
    "        if len(_data[column].unique()) < 10:\n",
    "            print(f'{column} unique values: {_data[column].unique()}')\n",
    "        else:\n",
    "            percent_unique = len(_data[column].unique()) / _data.shape[0] * 100\n",
    "            print(f'{column} % unique values: {percent_unique}')\n",
    "    print(_data.describe())\n",
    "    _data.hist()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.figure()  # new plot\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Only show for floats and ints\n",
    "\n",
    "    float_columns = _data.select_dtypes(include=['float64']).columns\n",
    "    int_columns = _data.select_dtypes(include=['int64']).columns\n",
    "    # Combine float and int columns\n",
    "\n",
    "    numeric_columns = float_columns.append(int_columns)\n",
    "    # Calculate correlation matrix\n",
    "    corMat = _data[numeric_columns].corr(method='pearson')\n",
    "\n",
    "    print(corMat)\n",
    "    ## plot correlation matrix as a heat map\n",
    "    sns.heatmap(corMat, square=True)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f\"CORRELATION MATRIX USING HEAT MAP\")\n",
    "    plt.show()\n",
    "\n",
    "    ## scatter plot of all _data\n",
    "    plt.figure()\n",
    "    # # The output overlaps itself, resize it to display better (w padding)\n",
    "    if show_scatter:\n",
    "        try:\n",
    "            scatter_matrix(_data)\n",
    "            plt.tight_layout(pad=0.1)\n",
    "            plt.show()\n",
    "        except:\n",
    "            return\n",
    "\n",
    "\n",
    "def data_info2(_date):\n",
    "    set_option('display.max_columns', None)\n",
    "    if not isinstance(_date, list):\n",
    "        if not isinstance(_date, tuple):\n",
    "            _date = ('', _date)\n",
    "        _date = [_date]\n",
    "    for name, data in _date:\n",
    "        print(f'{name} data')\n",
    "        print(data.info())\n",
    "        print(data.head(5))\n",
    "        for column in data.columns:\n",
    "            highlight_column = 'profile'\n",
    "            if column == highlight_column:\n",
    "                # print 2 rows of values completely\n",
    "                row1 = data.iloc[0][highlight_column]\n",
    "                row2 = data.iloc[1][highlight_column]\n",
    "                print(f'Row 1: {row1}')\n",
    "                print(f'Row 2: {row2}')\n",
    "            if len(data[column].unique()) < 10:\n",
    "                print(f'{column} unique values: {data[column].unique()}')\n",
    "            else:\n",
    "                percent_unique = len(data[column].unique()) / data.shape[0] * 100\n",
    "                print(f'{column} % unique values: {percent_unique}')\n",
    "        break"
   ],
   "id": "8928c8e52f143c64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_info(ks_data)",
   "id": "f76ed0deac37eec8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Theres a lot to clean up here. First we need to categorize each column, then determine what we need to change",
   "id": "f36092cd4084a922"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "columns_to_drop = ['Unnamed: 0', 'id', 'photo', 'name', 'blurb', 'slug', 'currency_symbol', 'currency_trailing_code', 'static_usd_rate', 'creator', 'profile', 'friends', 'is_backing', 'permissions', 'name_len', 'blurb_len', 'urls', 'source_url', 'location', 'is_starred', 'create_to_launch']\n",
    "float_columns = ['goal', 'pledged', 'usd_pledged']\n",
    "int_columns = ['backers_count', 'name_len_clean', 'blurb_len_clean',  'launch_to_deadline', 'launch_to_state_change', 'create_to_launch_days', 'launch_to_deadline_days', 'launch_to_state_change_days', ]\n",
    "datetime_columns = ['deadline', 'state_changed_at', 'created_at', 'launched_at']\n",
    "date_int_columns = ['deadline_month', 'deadline_day', 'deadline_hr', 'state_changed_at_month', 'state_changed_at_day', 'state_changed_at_month', 'state_changed_at_day', 'state_changed_at_yr', 'created_at_month', 'created_at_day', 'created_at_hr', 'launched_at_month', 'launched_at_day', 'launched_at_hr', 'state_changed_at_hr', 'created_at_yr', 'launched_at_yr']\n",
    "category_columns = ['state', 'currency', 'staff_pick', 'category', 'deadline_weekday', 'state_changed_at_weekday', 'created_at_weekday', 'launched_at_weekday', 'deadline_yr', 'country']\n",
    "boolean_columns = ['disable_communication', 'spotlight', 'SuccessfulBool', 'USorGB', 'TOPCOUNTRY', 'LaunchedTuesday', 'DeadlineWeekend']\n",
    "\n",
    "# This is just to categorize everything and make sure I'm not missing anything\n",
    "temp_data = ks_data.copy()\n",
    "data_info2(temp_data)\n",
    "temp_data = temp_data.drop(columns=columns_to_drop)\n",
    "temp_data = temp_data.drop(columns=datetime_columns)\n",
    "temp_data = temp_data.drop(columns=category_columns)\n",
    "temp_data = temp_data.drop(columns=boolean_columns)\n",
    "temp_data = temp_data.drop(columns=float_columns)\n",
    "temp_data = temp_data.drop(columns=int_columns)\n",
    "temp_data = temp_data.drop(columns=date_int_columns)\n",
    "print('\\n' * 3)\n",
    "print(f'Lets see what we have left')\n",
    "data_info2(('temp_data', temp_data))"
   ],
   "id": "f638a7aa59b4cf9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "kickstarter = ks_data.copy()\n",
    "#kickstarter = kickstarter.dropna()\n",
    "kickstarter = kickstarter.drop(columns=columns_to_drop)\n",
    "# Specifically examine the problematic columns\n",
    "print(\"NaN in name_len_clean:\", kickstarter['name_len_clean'].isna().sum())\n",
    "print(\"NaN in blurb_len_clean:\", kickstarter['blurb_len_clean'].isna().sum())\n",
    "\n",
    "print(kickstarter['category'].unique())\n",
    "# total number of records\n",
    "print(kickstarter.shape)\n",
    "# Number of na's in 'category'\n",
    "category_nas = kickstarter['category'].isna().sum()\n",
    "total_rows = kickstarter.shape[0]\n",
    "print(f'Category has {(category_nas / total_rows * 100):.2f}% as \"nan\"')\n",
    "temp_data = ks_data.copy()\n",
    "# Drop the 10 rows which have _len_clean as nan\n",
    "kickstarter = kickstarter.dropna(subset=['name_len_clean', 'blurb_len_clean'])\n",
    "print(\"NaN in name_len_clean:\", kickstarter['name_len_clean'].isna().sum())\n",
    "print(\"NaN in blurb_len_clean:\", kickstarter['blurb_len_clean'].isna().sum())\n",
    "\n",
    "kickstarter['name_len_clean'] = kickstarter['name_len_clean'].astype(int)\n",
    "kickstarter['blurb_len_clean'] = kickstarter['blurb_len_clean'].astype(int)\n",
    "\n",
    "# Replace 'nan' in category with 'None' (string not object), then do one-hot encoding\n",
    "kickstarter['category'] = kickstarter['category'].fillna(\"None\")\n",
    "print(kickstarter['category'].unique())"
   ],
   "id": "68fda2a70024d237",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def encode_categorical_features(df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"Encode all categorical features in the dataframe\"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df = df.copy()\n",
    "\n",
    "    # Get all categorical columns\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    print(f\"Categorical columns: {categorical_columns}\")\n",
    "\n",
    "    # Handle boolean columns separately\n",
    "    boolean_columns = ['staff_pick']\n",
    "    for col in boolean_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].replace({False: 0, True: 1})\n",
    "            print(f\"Converted boolean column: {col}\")\n",
    "\n",
    "    # Columns to one-hot encode\n",
    "    columns_to_encode = [\n",
    "        'category',\n",
    "        'deadline_weekday',\n",
    "        'created_at_weekday',\n",
    "        'launched_at_weekday'\n",
    "    ]\n",
    "\n",
    "    # Filter out columns that aren't in the dataframe\n",
    "    columns_to_encode = [col for col in columns_to_encode if col in df.columns]\n",
    "\n",
    "    # Remove 'state_changed_at_weekday' column if it exists\n",
    "    if 'state_changed_at_weekday' in df.columns:\n",
    "        df = df.drop(columns='state_changed_at_weekday')\n",
    "        print(\"Dropped 'state_changed_at_weekday' column\")\n",
    "\n",
    "    # One-hot encode the selected columns\n",
    "    all_encoded_dfs = []\n",
    "\n",
    "    for col in columns_to_encode:\n",
    "        encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        encoded = encoder.fit_transform(df[[col]])\n",
    "\n",
    "        # Create meaningful column names\n",
    "        encoded_cols = [f\"{col}_{c}\" for c in encoder.categories_[0]]\n",
    "        encoded_df = pd.DataFrame(encoded, columns=encoded_cols, index=df.index)\n",
    "\n",
    "        # Add to list of encoded dataframes\n",
    "        all_encoded_dfs.append(encoded_df)\n",
    "\n",
    "        # Drop the original column\n",
    "        print(f'Dropping original column: {col}')\n",
    "        df = df.drop(columns=col)\n",
    "        print(f\"Encoded column: {col} → {len(encoded_cols)} features\")\n",
    "\n",
    "    # Combine all dataframes\n",
    "    result = pd.concat([df] + all_encoded_dfs, axis=1)\n",
    "\n",
    "    # Create a list of all categorical columns (original and encoded)\n",
    "    all_categorical_columns = []\n",
    "    for col in categorical_columns:\n",
    "        if col in result.columns:\n",
    "            all_categorical_columns.append(col)\n",
    "        else:\n",
    "            # Add the encoded column names\n",
    "            all_categorical_columns.extend([c for c in result.columns if c.startswith(f\"{col}_\")])\n",
    "\n",
    "    print(f\"Total categorical columns after encoding: {len(all_categorical_columns)}\")\n",
    "\n",
    "    return result, all_categorical_columns\n",
    "\n",
    "# Example usage\n",
    "kickstarter, category_columns = encode_categorical_features(kickstarter)"
   ],
   "id": "45d9e7bec0ccfc6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Now we know what is in the data, let's look at some of the features and see if we can find any interesting patterns.",
   "id": "335ff1b8ac6cdc84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For each feature, lets see a histogram of the values and a boxplot of the values\n",
    "def plot_feature_distribution(data, feature):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(data[feature], bins=30, kde=True)\n",
    "    plt.title(f'{feature} Distribution')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=data[feature])\n",
    "    plt.title(f'{feature} Boxplot')\n",
    "    plt.xlabel(feature)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "columns_to_show = float_columns + int_columns\n",
    "\n",
    "for feature in kickstarter.columns:\n",
    "    if feature in columns_to_show and not DONT_RUN_LONG_CELLS:\n",
    "        plot_feature_distribution(kickstarter, feature)"
   ],
   "id": "1e82c2e1d387cd07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "columns_to_standardize = [ # Roughly normal\n",
    "    'name_len_clean', 'blurb_len_clean',\n",
    "    'deadline_month', 'deadline_day', 'deadline_hr',\n",
    "    'state_changed_at_month', 'state_changed_at_day', 'state_changed_at_hr',\n",
    "    'created_at_month', 'created_at_day', 'created_at_hr',\n",
    "    'launched_at_month', 'launched_at_day', 'launched_at_hr'\n",
    "]\n",
    "\n",
    "columns_to_log_transform = [ # Heavily right skewed\n",
    "    'goal', 'pledged', 'usd_pledged', 'backers_count',\n",
    "    'create_to_launch_days'\n",
    "]\n",
    "\n",
    "columns_to_normalize = [ # Different scales\n",
    "    'launch_to_deadline_days', 'launch_to_state_change_days'\n",
    "]\n",
    "\n",
    "columns_to_drop2 = [\n",
    "    # Temporal columns represented by better features\n",
    "    'deadline', 'state_changed_at', 'created_at', 'launched_at',\n",
    "    'launch_to_deadline', 'launch_to_state_change',\n",
    "\n",
    "    # Duplicate/redundant information\n",
    "    'deadline_yr', 'state_changed_at_yr', 'created_at_yr', 'launched_at_yr',\n",
    "\n",
    "    # Categorical with many unique values, better represented by other features\n",
    "    'country', 'currency',\n",
    "\n",
    "    # Low variance or binary columns that might be redundant\n",
    "    'disable_communication', 'spotlight',\n",
    "    'USorGB', 'TOPCOUNTRY', 'LaunchedTuesday', 'DeadlineWeekend'\n",
    "]\n",
    "\n",
    "# Drop the columns we don't want\n",
    "kickstarter = kickstarter.drop(columns=columns_to_drop2)\n",
    "print(kickstarter.columns)"
   ],
   "id": "92fbc8a05bd95a48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for column in columns_to_log_transform:\n",
    "    print(f\"NaN values in '{column}': {kickstarter[column].isna().sum()}\")\n",
    "\n",
    "print(kickstarter.shape[0])\n",
    "kickstarter = kickstarter.dropna(subset=columns_to_log_transform)\n",
    "print(kickstarter.shape[0])\n",
    "\n",
    "# Standardize the columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "for column in columns_to_standardize:\n",
    "    kickstarter[column] = scaler.fit_transform(kickstarter[[column]])\n",
    "\n",
    "# Log transform the columns\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import numpy as np\n",
    "log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "for column in columns_to_log_transform:\n",
    "    kickstarter[column] = log_transformer.fit_transform(kickstarter[[column]])\n",
    "# Normalize the columns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizer = MinMaxScaler()\n",
    "for column in columns_to_normalize:\n",
    "    kickstarter[column] = normalizer.fit_transform(kickstarter[[column]])"
   ],
   "id": "f539f238bb4ca2a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Check the data again\n",
    "data_info(kickstarter)"
   ],
   "id": "7ac8a63076b1304",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## We need to make a 'success' classifier, so lets take a look at the definition of success in the data",
   "id": "f17577a40d3a4a9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compare 'state' and 'SuccessfulBool' to see if they are the same\n",
    "print(ks_data['state'].unique())\n",
    "print(ks_data['SuccessfulBool'].unique())\n",
    "print(ks_data['state'].value_counts())\n",
    "print(ks_data['SuccessfulBool'].value_counts())\n",
    "# Make a table where the rows are 0/1 for SuccessfulBool and the columns are the states\n",
    "print(ks_data.groupby(['SuccessfulBool', 'state']).size().unstack())\n",
    "\n",
    "# Show the distribution of 'pledged/goal' to see if we can make a column called 'got_funded'\n",
    "temp_data = ks_data.copy()\n",
    "\n",
    "# confirm they're both numbers\n",
    "print(temp_data['pledged'].dtype)\n",
    "print(temp_data['goal'].dtype)\n",
    "\n",
    "# show the count where pledged > goal\n",
    "print(f'{temp_data[temp_data['pledged'] > temp_data['goal']].shape[0]} projects got funded')\n",
    "\n",
    "# Create got_funded column and show the histogram\n",
    "temp_data['got_funded'] = temp_data['pledged'] / temp_data['goal']\n",
    "\n",
    "# Describe the column\n",
    "print(temp_data['got_funded'].describe())\n",
    "\n",
    "# Get count of SuccessfulBool\n",
    "print(temp_data['SuccessfulBool'].value_counts())\n",
    "# Shows the same thing"
   ],
   "id": "cbe49b98a581051f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# So SuccessfulBool doesn't capture why it failed but does capture if it was successful and closely matches if the project was funded, but not how much it was funded.",
   "id": "5e156bc381eb952b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# using kickstarter data, show some good plots of features vs SuccessfulBool\n",
    "\n",
    "def plot_feature_vs_success(data, feature):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(data[data['SuccessfulBool'] == 1][feature], bins=30, kde=True, color='green', label='Successful')\n",
    "    sns.histplot(data[data['SuccessfulBool'] == 0][feature], bins=30, kde=True, color='red', label='Failed')\n",
    "    plt.title(f'{feature} vs SuccessfulBool')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=data['SuccessfulBool'], y=data[feature])\n",
    "    plt.title(f'{feature} vs SuccessfulBool')\n",
    "    plt.xlabel('SuccessfulBool')\n",
    "    plt.ylabel(feature)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show the features that are not categorical\n",
    "for feature in kickstarter.columns:\n",
    "    if DONT_RUN_LONG_CELLS:\n",
    "        break\n",
    "    if feature not in ['state', 'SuccessfulBool', 'category', 'currency', 'staff_pick']:\n",
    "        plot_feature_vs_success(kickstarter, feature)"
   ],
   "id": "8a896aabd35e3b24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Because `state` captures the same information as `SuccessfulBool`, we can drop it\n",
    "### and because `got_funded` and `pledged` offer information obtained at the end of the campaign, we should drop them as well"
   ],
   "id": "b9ab6fc3b04c30b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "kickstarter = kickstarter.drop(columns=['state', 'pledged'])",
   "id": "f9f182ff6edb0c6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Determine the avg goal for each category, save to a hashmap\n",
    "category_goals = {}\n",
    "\n",
    "temp_data = ks_data.copy()\n",
    "unique_categories = ks_data['category'].unique()\n",
    "unique_categories = np.delete(unique_categories, 2)\n",
    "unique_categories_list = unique_categories.tolist()\n",
    "unique_categories_list.append('None')\n",
    "unique_categories = np.array(unique_categories_list)\n",
    "\n",
    "print(unique_categories)\n",
    "\n",
    "for category in unique_categories:\n",
    "    # get the avg goal for the category\n",
    "    avg_goal = ks_data[ks_data['category'] == category]['goal'].mean()\n",
    "    # store as regular string and regular float\n",
    "    category_goals[category] = avg_goal\n",
    "\n",
    "print(category_goals)\n",
    "\n",
    "# Now make a new column, goal_percentile\n",
    "def make_percentile(goal_amount: float, category: str) -> float:\n",
    "    \"\"\"Return what percentile the goal is compared to average for its category\"\"\"\n",
    "    avg_for_category = category_goals.get(category, 0)\n",
    "    if avg_for_category == 0:\n",
    "        return 0\n",
    "\n",
    "    return goal_amount / avg_for_category * 100\n",
    "\n",
    "# Then apply the function to create a new column\n",
    "kickstarter['goal_percentile'] = ks_data.groupby('category')['goal'].transform(\n",
    "    lambda x: x.rank(pct=True)\n",
    ") * 100  # Scale to 0-100\n",
    "\n",
    "# Show the distribution of goal_percentile as a box plot\n",
    "def plot_goal_percentile_boxplot(data):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x=data['goal_percentile'])\n",
    "    plt.title('Goal Percentile Boxplot')\n",
    "    plt.xlabel('Goal Percentile')\n",
    "    plt.show()\n",
    "\n",
    "plot_goal_percentile_boxplot(kickstarter)"
   ],
   "id": "16a005f65095c879",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# make a new column funding_needed_per_day which is the goal / launch_to_deadline\n",
    "\n",
    "# Drop all rows with launch_to_deadline_days = 0\n",
    "kickstarter = kickstarter[kickstarter['launch_to_deadline_days'] != 0]\n",
    "\n",
    "kickstarter['funding_needed_per_day'] = kickstarter['goal'] / kickstarter['launch_to_deadline_days']\n",
    "# show the distribution of funding_needed_per_day\n",
    "def plot_funding_needed_per_day_boxplot(data):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x=data['funding_needed_per_day'])\n",
    "    plt.title('Funding Needed Per Day Boxplot')\n",
    "    plt.xlabel('Funding Needed Per Day')\n",
    "    plt.show()\n",
    "\n",
    "plot_funding_needed_per_day_boxplot(kickstarter)\n",
    "import numpy as np\n",
    "\n",
    "# 1. Check where the infinities or extreme values are\n",
    "print(\"Infinities in funding_needed_per_day:\", np.isinf(kickstarter['funding_needed_per_day']).sum())\n",
    "print(\"NaNs in funding_needed_per_day:\", np.isnan(kickstarter['funding_needed_per_day']).sum())\n",
    "print(\"Max value in funding_needed_per_day:\", kickstarter['funding_needed_per_day'].max())\n",
    "\n",
    "# 2. Check the source columns - likely a division by zero\n",
    "print(\"Zeros in launch_to_deadline_days:\", (kickstarter['launch_to_deadline_days'] == 0).sum())\n",
    "# Normalize it\n",
    "kickstarter['funding_needed_per_day'] = normalizer.fit_transform(kickstarter[['funding_needed_per_day']])\n",
    "\n",
    "plot_funding_needed_per_day_boxplot(kickstarter)\n"
   ],
   "id": "a7e96906da9e3ff5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(kickstarter.columns)",
   "id": "2d28e635fbe444e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from itertools import combinations\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "all_features = kickstarter.columns\n",
    "best_score = 0\n",
    "best_features = None\n",
    "X = kickstarter[all_features]\n",
    "Y1 = kickstarter['SuccessfulBool']\n",
    "X = X.drop(columns=['SuccessfulBool'])\n",
    "\n",
    "for i in range(1, len(all_features) + 1):\n",
    "    for feature_combo in combinations(all_features, i):\n",
    "        features = list(feature_combo)\n",
    "        X = kickstarter[features]\n",
    "        scores = cross_val_score(DecisionTreeRegressor(), X, Y1, cv=5, scoring='r2')\n",
    "        avg_score = np.mean(scores)\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_features = features\n",
    "\n",
    "print(f\"Best features: {best_features} with R² score: {best_score:.4f}\")"
   ],
   "id": "b2f6bb1269feb6c6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
